---
title: "Jobson et al. (2022)"
author: "**Katie Jobson**"
date: "`r Sys.Date()`"
output: 
  html_document: 
    number_sections: true
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
    self_contained: yes
    mode: selfcontained
    df_print: paged
    css: !expr here::here("style_kjobson.css")
knit: (function(inputFile, encoding) { 
      out_dir <- './';
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), out_dir, 'jobson2022.html')) })
---

# Language and the cerebellum: structural connectivity to the eloquent brain

This is the RMarkdown file associated with my 2022 paper entitled: "Language and the cerebellum: structural connectivity to the eloquent brain". This paper was published in the Neurobiology of Language journal in 2022. All associated data can be found at [my OSF page](https://osf.io/w649b/).

## Data

The data used in this paper are all from the [Human Connectome Project (HCP)](https://www.humanconnectome.org/) dataset.

All of the data is preprocessed up until eddy motion correction. For an in-depth description of the pre-preprocessing steps used, please see [this paper](https://pubmed.ncbi.nlm.nih.gov/23668970/).

A previous member of the Olson lab, Dr. Athnasia Metoki, took the data processing one step further, which I utilized for my paper: "Additionally, we further processed the dMRI data with FSL’s BEDPOSTX multi-shell, ball and zeppelins model (Hernández et al. 2013; Sotiropoulos et al. 2016) to model white matter fiber orientations and crossing fibers."

## Subjects

This is the subject list that was used in this paper. This was a randomly selected group of subjects that were balanced for gender. 

N = 100 (50 M, 50 F)


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
subjects="100206 100307 100408 100610 101006 101309 101410 102311 102513 102816 103111 103414 103515 103818 104012 104416 104820 105014 105115 105216 105620 105923 106016 106319 106521 107018 107321 107422 108121 108222 108323 108525 108828 109123 109830 110411 110613 111009 111312 111413 111514 111716 112112 112314 112516 112920 113215 113619 113922 114217 114419 114621 114823 115017 115320 115825 116221 116524 116726 117122 117324 117930 118124 118225 118528 118730 118932 119126 119732 119833 120212 120515 120717 121416 121618 121921 122317 122620 122822 123117 123521 123925 124220 124422 124624 124826 126325 126628 127630 127933 128026 128632 128935 129028 129129 129331 129634 129937 130316 130417 130619 130821 131217 131419 131722 131823 131924 132017 133019 133625 133827 133928 134021 134223 134425 134728 134829 135225 135730 135932 136732 136833 137229 137633 138231 138837 139233 139637 139839 140117 140319 140824 141119 141422 141826 143325 144125 144428 144731 144832 145127 145834 146129 146331 146432 146533 146937 147030 148032 148133 148335 148840 148941 149236 149337 149539 149741 149842 150625 150726 151223 151425 151526 151728 151829 152831 153025 153227 153429 154229 154431 154532 154734 154936 155231 155635 155938 156031 156233 156334 156435 156536 156637 157336 157437 157942 158035 158136 158338 158540 158843 159138 159239 159441 159744 159946 160123 160830 160931 161327"
```

## OwlsNest

In order to process this large of a dataset, we needed to use the supercomputing cloud at Temple University, called [OwlsNest](https://www.hpc.temple.edu/). Due to time constraints of the call for papers, we only processed 100 subjects.

Tutorials on how to use OwlsNest have been put on by Temple's Coding Outreach Group. You can find that tutorial [here](https://tu-coding-outreach-group.github.io/cog_summer_workshops_2021/linux-owlsnest/index.html).

## Running Scripts on OwlsNest

Many of my scripts include the necessary information to be able to submit scripts to the queue on OwlsNest. As I am showcasing my scripts, these will be included. It looks like this:

```{r, results=FALSE, warning=FALSE, eval=FALSE}
#!/bin/sh
#PBS -N probtrackx2
#PBS -q normal
#PBS -l walltime=24:00:00
#PBS -l nodes=1:ppn=28
#PBS -v subjects="100206 100307 100408 100610 101006 101309 101410 102311 102513 102816 103111 103414 103515 103818 104012 104416 104820 105014 105115 105216 105620 105923 106016 106319 106521 107018 107321 107422 108121 108222 108323 108525 108828 109123 109830 110411 110613 111009 111312 111413 111514 111716 112112 112314 112516 112920 113215 113619 113922 114217 114419 114621 114823 115017 115320 115825 116221 116524 116726 117122 117324 117930 118124 118225 118528 118730 118932 119126 119732 119833 120212 120515 120717 121416 121618 121921 122317 122620 122822 123117 123521 123925 124220 124422 124624 124826 126325 126628 127630 127933 128026 128632 128935 129028 129129 129331 129634 129937 130316 130417 130619 130821 131217 131419 131722 131823 131924 132017 133019 133625 133827 133928 134021 134223 134425 134728 134829 135225 135730 135932 136732 136833 137229 137633 138231 138837 139233 139637 139839 140117 140319 140824 141119 141422 141826 143325 144125 144428 144731 144832 145127 145834 146129 146331 146432 146533 146937 147030 148032 148133 148335 148840 148941 149236 149337 149539 149741 149842 150625 150726 151223 151425 151526 151728 151829 152831 153025 153227 153429 154229 154431 154532 154734 154936 155231 155635 155938 156031 156233 156334 156435 156536 156637 157336 157437 157942 158035 158136 158338 158540 158843 159138 159239 159441 159744 159946 160123 160830 160931 161327"
cd $PBS_O_WORKDIR
```

This sets up OwlsNest to run for 24 hours on the normal node using 28 cores on a single node. It also sets up global information in the script that we use later.

## Scripts

All of these scripts are submitted as bash scripts on OwlsNest. 

### First Script: A6.sh

The first step to analyzing this data was to run probabilistic tractography on the bedpostX data.

```{r, results=FALSE, warning=FALSE, eval=FALSE}
#!/bin/sh
#PBS -N probtrackx2
#PBS -q normal
#PBS -l walltime=24:00:00
#PBS -l nodes=1:ppn=28
#PBS -v subjects="100206 100307 100408 100610 101006 101309 101410 102311 102513 102816 103111 103414 103515 103818 104012 104416 104820 105014 105115 105216 105620 105923 106016 106319 106521 107018 107321 107422 108121 108222 108323 108525 108828 109123 109830 110411 110613 111009 111312 111413 111514 111716 112112 112314 112516 112920 113215 113619 113922 114217 114419 114621 114823 115017 115320 115825 116221 116524 116726 117122 117324 117930 118124 118225 118528 118730 118932 119126 119732 119833 120212 120515 120717 121416 121618 121921 122317 122620 122822 123117 123521 123925 124220 124422 124624 124826 126325 126628 127630 127933 128026 128632 128935 129028 129129 129331 129634 129937 130316 130417 130619 130821 131217 131419 131722 131823 131924 132017 133019 133625 133827 133928 134021 134223 134425 134728 134829 135225 135730 135932 136732 136833 137229 137633 138231 138837 139233 139637 139839 140117 140319 140824 141119 141422 141826 143325 144125 144428 144731 144832 145127 145834 146129 146331 146432 146533 146937 147030 148032 148133 148335 148840 148941 149236 149337 149539 149741 149842 150625 150726 151223 151425 151526 151728 151829 152831 153025 153227 153429 154229 154431 154532 154734 154936 155231 155635 155938 156031 156233 156334 156435 156536 156637 157336 157437 157942 158035 158136 158338 158540 158843 159138 159239 159441 159744 159946 160123 160830 160931 161327"
cd $PBS_O_WORKDIR

module load fsl/6.0.2
fslinit

touch cmd_probtrackx${PBS_JOBID}.txt

for s in ${subjects}
do
    for r in CB_r
    do
	for q in mPFC_l
	do
    echo probtrackx2 -x $HOME/cb_lang/data_set/${s}/seeds_targets/${r}.txt -l --onewaycondition -c 0.2 -S 2000 --steplength=0.5 -P 5000 --fibthresh=0.01 --distthresh=0.0 --sampvox=0.0 --forcedir --opd --ompl --modeuler --pd -s $HOME/cb_lang/data_set/${s}/dmri/merged --waypoints=/home/tuj96493/cb_lang/data_set/${s}/seeds_targets/waypoints_CTC_mPFC.txt --wtstop=/$HOME/cb_lang/data_set/${s}/seeds_targets/${q}.txt --avoid=$HOME/cb_lang/data_set/${s}/masks/relationship_knowledge/frontal_exclusion_CTC_ns_bin.nii.gz -m $HOME/cb_lang/data_set/${s}/nodif_brain_mask.nii.gz --dir=$HOME/work/relationship_knowledge/derivatives/probtrackx/${s}/${r}_${q} >> cmd_probtrackx${PBS_JOBID}.txt
done
 done
    done

torque-launch -p chkpt_probtrackx${PBS_JOBID}.txt cmd_probtrackx${PBS_JOBID}.txt
```

### Second Script: A7.sh

The second script was used to create the transformation matrices used


```{r, results=FALSE, warning=FALSE, eval=FALSE}
#!/bin/sh
#PBS -N probtrackx2
#PBS -q normal
#PBS -l walltime=24:00:00
#PBS -l nodes=1:ppn=28
#PBS -v subjects="100206 100307 100408 100610 101006 101309 101410 102311 102513 102816 103111 103414 103515 103818 104012 104416 104820 105014 105115 105216 105620 105923 106016 106319 106521 107018 107321 107422 108121 108222 108323 108525 108828 109123 109830 110411 110613 111009 111312 111413 111514 111716 112112 112314 112516 112920 113215 113619 113922 114217 114419 114621 114823 115017 115320 115825 116221 116524 116726 117122 117324 117930 118124 118225 118528 118730 118932 119126 119732 119833 120212 120515 120717 121416 121618 121921 122317 122620 122822 123117 123521 123925 124220 124422 124624 124826 126325 126628 127630 127933 128026 128632 128935 129028 129129 129331 129634 129937 130316 130417 130619 130821 131217 131419 131722 131823 131924 132017 133019 133625 133827 133928 134021 134223 134425 134728 134829 135225 135730 135932 136732 136833 137229 137633 138231 138837 139233 139637 139839 140117 140319 140824 141119 141422 141826 143325 144125 144428 144731 144832 145127 145834 146129 146331 146432 146533 146937 147030 148032 148133 148335 148840 148941 149236 149337 149539 149741 149842 150625 150726 151223 151425 151526 151728 151829 152831 153025 153227 153429 154229 154431 154532 154734 154936 155231 155635 155938 156031 156233 156334 156435 156536 156637 157336 157437 157942 158035 158136 158338 158540 158843 159138 159239 159441 159744 159946 160123 160830 160931 161327"
cd $PBS_O_WORKDIR

module load fsl/6.0.2
fslinit

rm -f *${PBS_JOBID}.txt

for n in mkdir diff2str str2diff str2standard other
do
touch cmd_${n}${PBS_JOBID}.txt
done

for s in ${subjects}
do

echo mkdir ~/cbptools/data_set/${s}/xfms >> cmd_mkdir${PBS_JOBID}.txt
    
echo flirt -in ~/cb_lang/data_set/${s}/nodif_brain_mask.nii.gz  -ref ~/cb_lang/data_set/${s}/T1w_brain_mask.nii.gz -omat ~/cb_lang/data_set/${s}/xfms/diff2str.mat -searchrx -90 90 -searchry -90 90 -searchrz -90 90 -dof 6 -cost corratio >> cmd_diff2str${PBS_JOBID}.txt

echo convert_xfm -omat ~/cb_lang/data_set/${s}/xfms/str2diff.mat -inverse ~/cb_lang/data_set/${s}/xfms/diff2str.mat >> cmd_str2diff${PBS_JOBID}.txt

echo flirt -in ~/cb_lang/data_set/${s}/T1w_brain_mask.nii.gz -ref $HOME/relationship_knowledge/2mm_brainmask.nii.gz -omat ~/cb_lang/data_set/${s}/xfms/str2standard_lin.mat -searchrx -90 90 -searchry -90 90 -searchrz -90 90 -dof 12 -cost corratio >> cmd_str2standard${PBS_JOBID}.txt

echo convert_xfm -omat ~/cb_lang/data_set/${s}/xfms/standard2str_lin.mat -inverse ~/cb_lang/data_set/${s}/xfms/str2standard_lin.mat $'\n'convert_xfm -omat ~/cb_lang/data_set/${s}/xfms/diff2standard_lin.mat -concat ~/cb_lang/data_set/${s}/xfms/str2standard_lin.mat ~/cb_lang/data_set/${s}/xfms/diff2str.mat $'\n'convert_xfm -omat ~/cb_lang/data_set/${s}/xfms/standard2diff_lin.mat -inverse ~/cb_lang/data_set/${s}/xfms/diff2standard_lin.mat >> cmd_other${PBS_JOBID}.txt
done

for n in diff2str str2diff str2standard other
do
torque-launch cmd_${n}${PBS_JOBID}.txt
done
```
